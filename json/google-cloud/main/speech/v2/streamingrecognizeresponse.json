{"id":"speech\/v2\/streamingrecognizeresponse","type":"","title":"Google\\Cloud\\Speech\\V2\\StreamingRecognizeResponse","name":"StreamingRecognizeResponse","description":"<p><code>StreamingRecognizeResponse<\/code> is the only message returned to the client by\n<code>StreamingRecognize<\/code>. A series of zero or more <code>StreamingRecognizeResponse<\/code>\nmessages are streamed back to the client. If there is no recognizable\naudio then no messages are streamed back to the client.<\/p>\n<p>Here are some examples of <code>StreamingRecognizeResponse<\/code>s that might\nbe returned while processing audio:<\/p>\n<ol>\n<li>results { alternatives { transcript: &quot;tube&quot; } stability: 0.01 }<\/li>\n<li>results { alternatives { transcript: &quot;to be a&quot; } stability: 0.01 }<\/li>\n<li>results { alternatives { transcript: &quot;to be&quot; } stability: 0.9 }\nresults { alternatives { transcript: &quot; or not to be&quot; } stability: 0.01 }<\/li>\n<li>results { alternatives { transcript: &quot;to be or not to be&quot;\nconfidence: 0.92 }\nalternatives { transcript: &quot;to bee or not to bee&quot; }\nis_final: true }<\/li>\n<li>results { alternatives { transcript: &quot; that's&quot; } stability: 0.01 }<\/li>\n<li>results { alternatives { transcript: &quot; that is&quot; } stability: 0.9 }\nresults { alternatives { transcript: &quot; the question&quot; } stability: 0.01 }<\/li>\n<li>results { alternatives { transcript: &quot; that is the question&quot;\nconfidence: 0.98 }\nalternatives { transcript: &quot; that was the question&quot; }\nis_final: true }\nNotes:\n<ul>\n<li>Only two of the above responses #4 and #7 contain final results; they are\nindicated by <code>is_final: true<\/code>. Concatenating these together generates the\nfull transcript: &quot;to be or not to be that is the question&quot;.<\/li>\n<li>The others contain interim <code>results<\/code>. #3 and #6 contain two interim\n<code>results<\/code>: the first portion has a high stability and is less likely to\nchange; the second portion has a low stability and is very likely to\nchange. A UI designer might choose to show only high stability <code>results<\/code>.<\/li>\n<li>The specific <code>stability<\/code> and <code>confidence<\/code> values shown above are only for\nillustrative purposes. Actual values may vary.<\/li>\n<li>In each response, only one of these fields will be set:\n<code>error<\/code>,\n<code>speech_event_type<\/code>, or\none or more (repeated) <code>results<\/code>.<\/li>\n<\/ul><\/li>\n<\/ol>\n<p>Generated from protobuf message <code>google.cloud.speech.v2.StreamingRecognizeResponse<\/code><\/p>\n<p>Extends <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Internal\/Message.php\" target=\"_blank\">Google\\Protobuf\\Internal\\Message<\/a><\/p>","examples":[],"resources":[],"methods":[{"id":"__construct","type":"constructor","name":"__construct","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L105","description":"<p>Constructor.<\/p>","examples":[],"resources":[],"params":[{"name":"data","description":"<p>Optional. Data for populating the Message object.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>"],"optional":false,"nullable":null},{"name":"data.results\n","description":"<p>This repeated list contains zero or more results that correspond to consecutive portions of the audio currently being processed. It contains zero or one [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>true<\/code> result (the newly settled portion), followed by zero or more [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>false<\/code> results (the interim results).<\/p>","types":["<a data-custom-type=\"speech\/v2\/streamingrecognitionresult\">Google\\Cloud\\Speech\\V2\\StreamingRecognitionResult[]<\/a>","<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Internal\/RepeatedField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\RepeatedField<\/a>"],"optional":null,"nullable":null},{"name":"data.speech_event_type\n","description":"<p>Indicates the type of speech event.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.integer.php\" target=\"_blank\">int<\/a>"],"optional":null,"nullable":null},{"name":"data.speech_event_offset\n","description":"<p>Time offset between the beginning of the audio and event emission.<\/p>","types":["<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Duration.php\" target=\"_blank\">Google\\Protobuf\\Duration<\/a>"],"optional":null,"nullable":null},{"name":"data.metadata\n","description":"<p>Metadata about the recognition.<\/p>","types":["<a data-custom-type=\"speech\/v2\/recognitionresponsemetadata\">Google\\Cloud\\Speech\\V2\\RecognitionResponseMetadata<\/a>"],"optional":null,"nullable":null}],"exceptions":[],"returns":[]},{"id":"getResults","type":"instance","name":"getResults","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L122","description":"<p>This repeated list contains zero or more results that\ncorrespond to consecutive portions of the audio currently being processed.<\/p>\n<p>It contains zero or one\n[is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>true<\/code>\nresult (the newly settled portion), followed by zero or more\n[is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>false<\/code>\nresults (the interim results).<\/p>\n<p>Generated from protobuf field <code>repeated .google.cloud.speech.v2.StreamingRecognitionResult results = 6;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Internal\/RepeatedField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\RepeatedField<\/a>"],"description":""}]},{"id":"setResults","type":"instance","name":"setResults","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L140","description":"<p>This repeated list contains zero or more results that\ncorrespond to consecutive portions of the audio currently being processed.<\/p>\n<p>It contains zero or one\n[is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>true<\/code>\nresult (the newly settled portion), followed by zero or more\n[is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>false<\/code>\nresults (the interim results).<\/p>\n<p>Generated from protobuf field <code>repeated .google.cloud.speech.v2.StreamingRecognitionResult results = 6;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>This repeated list contains zero or more results that\ncorrespond to consecutive portions of the audio currently being processed.<\/p>\n<p>It contains zero or one\n[is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>true<\/code>\nresult (the newly settled portion), followed by zero or more\n[is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=<code>false<\/code>\nresults (the interim results).<\/p>\n","types":["<a data-custom-type=\"speech\/v2\/streamingrecognitionresult\">Google\\Cloud\\Speech\\V2\\StreamingRecognitionResult[]<\/a>","<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Internal\/RepeatedField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\RepeatedField<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v2\/streamingrecognizeresponse\">Google\\Cloud\\Speech\\V2\\StreamingRecognizeResponse<\/a>"],"description":""}]},{"id":"getSpeechEventType","type":"instance","name":"getSpeechEventType","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L154","description":"<p>Indicates the type of speech event.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.speech.v2.StreamingRecognizeResponse.SpeechEventType speech_event_type = 3;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.integer.php\" target=\"_blank\">int<\/a>"],"description":""}]},{"id":"setSpeechEventType","type":"instance","name":"setSpeechEventType","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L166","description":"<p>Indicates the type of speech event.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.speech.v2.StreamingRecognizeResponse.SpeechEventType speech_event_type = 3;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Indicates the type of speech event.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.integer.php\" target=\"_blank\">int<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v2\/streamingrecognizeresponse\">Google\\Cloud\\Speech\\V2\\StreamingRecognizeResponse<\/a>"],"description":""}]},{"id":"getSpeechEventOffset","type":"instance","name":"getSpeechEventOffset","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L180","description":"<p>Time offset between the beginning of the audio and event emission.<\/p>\n<p>Generated from protobuf field <code>.google.protobuf.Duration speech_event_offset = 7;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Duration.php\" target=\"_blank\">Google\\Protobuf\\Duration<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setSpeechEventOffset","type":"instance","name":"setSpeechEventOffset","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L202","description":"<p>Time offset between the beginning of the audio and event emission.<\/p>\n<p>Generated from protobuf field <code>.google.protobuf.Duration speech_event_offset = 7;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Time offset between the beginning of the audio and event emission.<\/p>\n","types":["<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.21.10\/src\/Google\/Protobuf\/Duration.php\" target=\"_blank\">Google\\Protobuf\\Duration<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v2\/streamingrecognizeresponse\">Google\\Cloud\\Speech\\V2\\StreamingRecognizeResponse<\/a>"],"description":""}]},{"id":"getMetadata","type":"instance","name":"getMetadata","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L216","description":"<p>Metadata about the recognition.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.speech.v2.RecognitionResponseMetadata metadata = 5;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v2\/recognitionresponsemetadata\">Google\\Cloud\\Speech\\V2\\RecognitionResponseMetadata<\/a>","<a href=\"http:\/\/php.net\/manual\/en\/language.types.null.php\" target=\"_blank\">null<\/a>"],"description":""}]},{"id":"setMetadata","type":"instance","name":"setMetadata","source":"Speech\/src\/V2\/StreamingRecognizeResponse.php#L238","description":"<p>Metadata about the recognition.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.speech.v2.RecognitionResponseMetadata metadata = 5;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Metadata about the recognition.<\/p>\n","types":["<a data-custom-type=\"speech\/v2\/recognitionresponsemetadata\">Google\\Cloud\\Speech\\V2\\RecognitionResponseMetadata<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"speech\/v2\/streamingrecognizeresponse\">Google\\Cloud\\Speech\\V2\\StreamingRecognizeResponse<\/a>"],"description":""}]}]}